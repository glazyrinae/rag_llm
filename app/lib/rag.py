# app/rag_system.py
import os
import ast
from typing import List, Dict, Any
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Qdrant
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from qdrant_client import QdrantClient


class Rag:
    def __init__(
        self,
        embeddings: str = "sentence-transformers/all-mpnet-base-v2",
        cache_dir: str = "/app/embedding_models",
    ):
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫—ç—à–∞, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(cache_dir, exist_ok=True)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Qdrant –∫–ª–∏–µ–Ω—Ç–∞
        self.qdrant_client = QdrantClient(
            host=os.getenv("QDRANT_HOST", "localhost"),
            port=int(os.getenv("QDRANT_PORT", "6333")),
        )

        # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∫–æ–¥–∞ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        self.embeddings = HuggingFaceEmbeddings(
            model_name=embeddings,
            cache_folder=cache_dir,  # –õ–æ–∫–∞–ª—å–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —Ç–∞–º –ª–µ–∂–∏—Ç –æ–Ω –Ω–µ –±—É–¥–µ—Ç —Å–∫–∞—á–∏–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ
            model_kwargs={"device": "cpu"},  # –∏–ª–∏ 'cuda' –µ—Å–ª–∏ –µ—Å—Ç—å GPU
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –º–æ–¥–µ–ª—å –ª–æ–∫–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –Ω–µ—Ç - —Å–∫–∞—á–∏–≤–∞–µ–º
        # self._ensure_embeddings_available(embeddings, cache_dir)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
        self.vector_store = Qdrant(
            client=self.qdrant_client,
            collection_name="python_code",
            embeddings=self.embeddings,
        )

        # –°–ø–ª–∏—Ç—Ç–µ—Ä –¥–ª—è Python –∫–æ–¥–∞
        self.code_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=150,
            separators=[
                "\n\nclass ",
                "\n\ndef ",
                "\n\nasync def ",
                "\n\n# ",
                "\n\n",
                "\n",
                " ",
            ],
            length_function=len,
        )

        self.llm = None

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
    def init_llm(self, api_key: str, model: str = "mistralai/mistral-7b-instruct"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±–ª–∞—á–Ω–æ–π LLM"""
        self.llm = ChatOpenAI(
            openai_api_key=api_key,
            model_name=model,
            openai_api_base="https://openrouter.ai/api/v1",
            temperature=0.1,
            max_tokens=1000,
        )

    def scan_python_project(self, project_path: str) -> List[Document]:
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ Python –ø—Ä–æ–µ–∫—Ç–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–¥–∞"""
        documents = []

        for root, dirs, files in os.walk(project_path):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            dirs[:] = [
                d
                for d in dirs
                if not d.startswith(".") and d not in ["__pycache__", "venv", "env"]
            ]

            for file in files:
                if file.endswith(".py"):
                    file_path = os.path.join(root, file)
                    file_docs = self._parse_python_file(file_path)
                    documents.extend(file_docs)
                    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω: {file_path} ({len(file_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)")

        return documents

    def _parse_python_file(self, file_path: str) -> List[Document]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ Python —Ñ–∞–π–ª–∞"""
        documents = []

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # –ë–∞–∑–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å –ø–æ–ª–Ω—ã–º –∫–æ–¥–æ–º
            relative_path = os.path.relpath(file_path)
            full_doc = Document(
                page_content=f"–§–∞–π–ª: {relative_path}\n\n{content}",
                metadata={
                    "file_path": relative_path,
                    "type": "full_file",
                    "language": "python",
                },
            )
            documents.append(full_doc)

            # –ê–Ω–∞–ª–∏–∑ AST –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            try:
                tree = ast.parse(content)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª–∞—Å—Å—ã
                for node in ast.walk(tree):
                    if isinstance(node, ast.ClassDef):
                        class_code = ast.get_source_segment(content, node)
                        class_doc = Document(
                            page_content=f"–ö–ª–∞—Å—Å {node.name} –≤ —Ñ–∞–π–ª–µ {relative_path}:\n\n{class_code}",
                            metadata={
                                "file_path": relative_path,
                                "type": "class",
                                "name": node.name,
                                "language": "python",
                            },
                        )
                        documents.append(class_doc)

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ—É–Ω–∫—Ü–∏–∏
                    elif isinstance(node, ast.FunctionDef):
                        func_code = ast.get_source_segment(content, node)
                        func_doc = Document(
                            page_content=f"–§—É–Ω–∫—Ü–∏—è {node.name} –≤ —Ñ–∞–π–ª–µ {relative_path}:\n\n{func_code}",
                            metadata={
                                "file_path": relative_path,
                                "type": "function",
                                "name": node.name,
                                "language": "python",
                            },
                        )
                        documents.append(func_doc)

            except SyntaxError as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ AST –≤ {file_path}: {e}")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {e}")

        return documents

    def add_documents_to_vectorstore(self, documents: List[Document]):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î"""
        if not documents:
            raise ValueError("–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏
        chunks = self.code_splitter.split_documents(documents)
        print(f"üìÑ –°–æ–∑–¥–∞–Ω–æ {len(chunks)} –∫–æ–¥-—á–∞–Ω–∫–æ–≤")

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î
        self.vector_store.add_documents(chunks)
        print("‚úÖ –ö–æ–¥ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î")

    def create_code_qa_chain(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ QA —Ü–µ–ø–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–¥–æ–º"""
        if not self.llm:
            raise ValueError("LLM –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

        # –ü—Ä–æ–º–ø—Ç –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
        prompt_template = """–¢—ã - –æ–ø—ã—Ç–Ω—ã–π Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–ö–û–ù–¢–ï–ö–°–¢ –ö–û–î–ê:
{context}

–í–û–ü–†–û–°: {question}

–û—Ç–≤–µ—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–¥—Ä–æ–±–Ω–æ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏ –≥—Ä–∞–º–æ—Ç–Ω–æ. –ï—Å–ª–∏ –≤ –∫–æ–¥–µ –µ—Å—Ç—å –ø—Ä–∏–º–µ—Ä—ã - –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –æ–±—ä—è—Å–Ω–∏—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É - —Å–¥–µ–ª–∞–π —ç—Ç–æ.

–û–¢–í–ï–¢:"""

        prompt = PromptTemplate(
            template=prompt_template, input_variables=["context", "question"]
        )

        return RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vector_store.as_retriever(
                search_type="similarity", search_kwargs={"k": 6}
            ),
            chain_type_kwargs={"prompt": prompt},
            return_source_documents=True,
        )

    def ask_about_code(self, question: str) -> Dict[str, Any]:
        """–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ –∫–æ–¥–µ"""
        qa_chain = self.create_code_qa_chain()
        return qa_chain({"query": question})
